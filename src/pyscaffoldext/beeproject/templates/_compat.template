# -*- coding: utf-8 -*-


import os
import re
import time
import sys
import yaml
import logging
from logging.handlers import TimedRotatingFileHandler, RotatingFileHandler

__all__ = ['logger', 'project_config_object']


BASE_DIR = os.path.dirname(os.path.abspath(__file__))

DEFAULT_FORMAT = '%(asctime)s\tpid:%(process)d\t%(name)s\t%(filename)s[line:%(lineno)d]\t%(levelname)s\t%(message)s'


class DictToObj(object):
    def __init__(self, d):
        for a, b in d.items():
            if isinstance(b, (list, tuple)):
                setattr(self, a, [DictToObj(x) if isinstance(
                    x, dict) else x for x in b])
            else:
                setattr(self, a, DictToObj(b) if isinstance(b, dict) else b)


class FileLock(object):
    """ A file locking mechanism that has context-manager support so  
        you can use it in a with statement. This should be relatively cross 
        compatible as it doesn't rely on msvcrt or fcntl for the locking. 
    """

    def __init__(self, file_name, timeout=2, delay=.05):
        """ Prepare the file locker. Specify the file to lock and optionally 
            the maximum timeout and the delay between each attempt to lock. 
        """
        self.is_locked = False
        self.lockfile = os.path.join(os.getcwd(), "%s.lock" % file_name)
        self.file_name = file_name
        self.timeout = timeout
        self.delay = delay

    def acquire(self):
        """ Acquire the lock, if possible. If the lock is in use, it check again 
            every `wait` seconds. It does this until it either gets the lock or 
            exceeds `timeout` number of seconds, in which case it throws  
            an exception. 
        """
        start_time = time.time()
        while True:
            try:
                # 独占式打开文件
                self.fd = os.open(self.lockfile, os.O_CREAT |
                                  os.O_EXCL | os.O_RDWR)
                break
            except OSError as e:
                time.sleep(self.delay)
        self.is_locked = True

    def release(self):
        """ Get rid of the lock by deleting the lockfile.  
            When working in a `with` statement, this gets automatically  
            called at the end. 
        """
        # 关闭文件，删除文件
        if self.is_locked:
            os.close(self.fd)
            os.unlink(self.lockfile)
            self.is_locked = False

    def __enter__(self):
        """ Activated when used in the with statement.  
            Should automatically acquire a lock to be used in the with block. 
        """
        if not self.is_locked:
            self.acquire()
        return self

    def __exit__(self, type, value, traceback):
        """ Activated at the end of the with statement. 
            It automatically releases the lock if it isn't locked. 
        """
        if self.is_locked:
            self.release()

    def __del__(self):
        """ Make sure that the FileLock instance doesn't leave a lockfile 
            lying around. 
        """
        self.release()


_MIDNIGHT = 24 * 60 * 60  # number of seconds in a day


class SafeTimedRotatingFileHandler(TimedRotatingFileHandler):
    """
    Handler for logging to a file, rotating the log file at certain timed
    intervals.

    If backupCount is > 0, when rollover is done, no more than backupCount
    files are kept - the oldest ones are deleted.
    """

    def __init__(self, filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None):
        TimedRotatingFileHandler.__init__(
            self, filename, when, interval, backupCount, encoding, delay, utc, atTime)

    def doRollover(self):
        """
        do a rollover; in this case, a date/time stamp is appended to the filename
        when the rollover happens.  However, you want the file to be named for the
        start of the interval, not the current time.  If there is a backup count,
        then we have to get a list of matching filenames, sort them and remove
        the one with the oldest suffix.
        """
        if self.stream:
            self.stream.close()
            self.stream = None
        # get the time that this sequence started at and make it a TimeTuple
        currentTime = int(time.time())
        dstNow = time.localtime(currentTime)[-1]
        t = self.rolloverAt - self.interval
        if self.utc:
            timeTuple = time.gmtime(t)
        else:
            timeTuple = time.localtime(t)
            dstThen = timeTuple[-1]
            if dstNow != dstThen:
                if dstNow:
                    addend = 3600
                else:
                    addend = -3600
                timeTuple = time.localtime(t + addend)
        # dfn = self.rotation_filename(self.baseFilename + "." + time.strftime(self.suffix, timeTuple))
        # if os.path.exists(dfn):
        #     os.remove(dfn)
        # self.rotate(self.baseFilename, dfn)
        # if self.backupCount > 0:
        #     for s in self.getFilesToDelete():
        #         os.remove(s)
        ### changed ###
        dfn = self.baseFilename + "." + time.strftime(self.suffix, timeTuple)
        if not os.path.exists(dfn) and os.path.exists(self.baseFilename):
            with FileLock(self.baseFilename):
                os.rename(self.baseFilename, dfn)
        if self.backupCount > 0:
            for s in self.getFilesToDelete():
                try:
                    os.remove(s)
                except Exception as e:
                    pass
        ### changed ###
        if not self.delay:
            self.stream = self._open()
        newRolloverAt = self.computeRollover(currentTime)
        while newRolloverAt <= currentTime:
            newRolloverAt = newRolloverAt + self.interval
        # If DST changes and midnight or weekly rollover, adjust for this.
        if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:
            dstAtRollover = time.localtime(newRolloverAt)[-1]
            if dstNow != dstAtRollover:
                if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour
                    addend = -3600
                else:           # DST bows out before next rollover, so we need to add an hour
                    addend = 3600
                newRolloverAt += addend
        self.rolloverAt = newRolloverAt


def create_logger(project_name, confdict={}, modulepath=''):
    """创建全局性的logger对象.

    创建一个以{project_name}为名称的logger对象,logger的存放路径和TimeRotating的参数设置通过{confdict}设定,
    如果是项目中的子模块需要进行development,那么会获取项目至子模块的目录路径,从而再日志存放目录下也已经该目录路径创建
    目录,将子模块的日志存放在与该子模块目录名相同的日志目录下.

    Parameters
    ----------
    project_name : [string]
        执行项目或模块的目录名称
    confdict : [dict]
        对TimeRotating需要的参数设定, by default {}
    modulepath : str, optional
        模块相对整个项目的目录路径, by default ''

    Returns
    -------
    [object]
        logger 对象
    """
    if not hasattr(confdict, 'get'):
        raise Exception('logging config error!')
    if 'dirpath' in confdict.keys():
        dirpath = confdict.get('dirpath')
    else:
        dirpath = '/tmp/logs'
    if not modulepath:
        logger_dir = os.path.join(dirpath, project_name)
    else:
        logger_dir = os.path.join(dirpath, modulepath, project_name)
    if not os.path.exists(logger_dir):
        try:
            os.makedirs(logger_dir)
        except Exception as e:
            raise Exception(e)
    if 'debug' in confdict.keys():
        isdebug = confdict.get('debug')
    else:
        isdebug = False

    timerotating_params = {
        'when': 'midnight' if 'when' not in confdict.keys() else confdict['when'],
        'interval': 1,
        'backupCount': 6 if 'backupCount' not in confdict.keys() else int(confdict['backupCount']),
        'encoding': 'utf-8',
        'delay': False,
        'utc': False,
        'atTime': None,
    }
    info_filepath = os.path.join(logger_dir, project_name + '.log')
    error_filepath = os.path.join(logger_dir, "error_" + project_name + '.log')
    # 创建handler
    streamhandler = logging.StreamHandler()
    info_filehandler = SafeTimedRotatingFileHandler(
        info_filepath, **timerotating_params)
    timerotating_params['when'] = 'w6'
    error_filehandler = SafeTimedRotatingFileHandler(
        error_filepath, **timerotating_params)
    # info_filehandler = TimedRotatingFileHandler(
    #     info_filepath, **timerotating_params)
    # timerotating_params['when'] = 'w6'
    # error_filehandler = TimedRotatingFileHandler(
    #     error_filepath, **timerotating_params)

    # 设置level
    streamhandler.setLevel(logging.DEBUG)
    info_filehandler.setLevel(logging.DEBUG)
    error_filehandler.setLevel(logging.ERROR)

    # 设置format
    logformat = logging.Formatter(DEFAULT_FORMAT)
    streamhandler.setFormatter(logformat)
    info_filehandler.setFormatter(logformat)
    error_filehandler.setFormatter(logformat)

    # 创建logger
    logger = logging.getLogger(project_name)
    logger.setLevel(logging.DEBUG)

    # addHandler
    logger.addHandler(streamhandler)
    logger.addHandler(info_filehandler)
    logger.addHandler(error_filehandler)

    # add filter
    if not isdebug:
        info_filehandler.addFilter(type('', (logging.Filter,), {'filter': staticmethod(
            lambda r: r.levelno == logging.INFO or r.levelno == logging.WARNING)}))
    else:
        info_filehandler.addFilter(type('', (logging.Filter,), {'filter': staticmethod(
            lambda r: r.levelno <= logging.WARNING)}))

    # existing
    # logger.disabled = False
    if not isdebug:
        logging.disable(logging.DEBUG)
    # propagate
    logger.propagate = False

    return logger


##################
# logging config #
##################

def _auto_compatible_logger_and_yaml():
    project_config_object = DictToObj({})
    isproject = False if os.path.exists(
        os.path.join(os.path.dirname(BASE_DIR), '__init__.py')) else True
    if isproject:
        project_name = os.path.dirname(BASE_DIR).split('/')[-1]
        module_name = BASE_DIR.split('/')[-1]
        project_logging_config = {}
        project_config_file = os.path.join(BASE_DIR, 'project_config.yaml')
        if os.path.exists(project_config_file):
            try:
                with open(project_config_file, 'r') as yamlf:
                    allcfg = yaml.safe_load(yamlf)
                global_cfg = DictToObj(allcfg)
                if os.environ.get('PRODUCTION_ENVIRONMENT', None):
                    project_config_object = global_cfg.production
                else:
                    project_config_object = global_cfg.development
                project_logging_config = project_config_object.logging.__dict__
            except Exception as e:
                raise Exception(e)
        mdpath = '/'.join([project_name])
        logger = create_logger(module_name, project_logging_config, mdpath)

    else:
        module_name = BASE_DIR.split('/')[-1]
        project_log_name = BASE_DIR.split('/')[-2]
        project_dirname = ''
        path_name = BASE_DIR.split('/')
        for idx, name in enumerate(path_name):
            if idx and os.path.isdir(os.path.join('/', '/'.join(path_name[:idx]), name)):
                if not os.path.exists(os.path.join('/', '/'.join(path_name[:idx]), name, '__init__.py')):
                    project_dirname = name
            if name == BASE_DIR.split('/')[-2]:
                break
            if not name or name == 'root' or not logging.getLogger(name).hasHandlers():
                continue
            if logging.getLogger('.'.join([name, path_name[idx+1]])).hasHandlers():
                project_log_name = name
                break
        if project_dirname:
            module_dirname = '/'.join(path_name[:path_name.index(project_dirname) + 2])
            project_config_file = os.path.join(module_dirname, 'project_config.yaml')
            if os.path.exists(project_config_file):
                try:
                    with open(project_config_file, 'r') as yamlf:
                        allcfg = yaml.safe_load(yamlf)
                    global_cfg = DictToObj(allcfg)
                    if os.environ.get('PRODUCTION_ENVIRONMENT', None):
                        project_config_object = global_cfg.production
                    else:
                        project_config_object = global_cfg.development
                except Exception as e:
                    pass
        # sub module logging
        if logging.getLogger(project_log_name).hasHandlers():
            log_name = '.'.join(path_name[path_name.index(project_log_name):])
            logger = logging.getLogger(log_name)
        else:
            # project -> module path
            mdpath = '/'.join(path_name[path_name.index(project_dirname): path_name.index(module_name)])
            # Custom logging configuration.
            confdict = {
                'dirpath': '/tmp/logs',
                'debug': True,
            }
            logger = create_logger(module_name, confdict, mdpath)
    return logger, project_config_object


# auto execute
logger, project_config_object = _auto_compatible_logger_and_yaml()
